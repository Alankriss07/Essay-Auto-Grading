{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-25T10:04:28.188808Z","iopub.execute_input":"2022-11-25T10:04:28.189422Z","iopub.status.idle":"2022-11-25T10:04:28.200376Z","shell.execute_reply.started":"2022-11-25T10:04:28.189390Z","shell.execute_reply":"2022-11-25T10:04:28.198995Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nimport statistics\nimport numpy as np\nimport pickle as pkl\nfrom sklearn.metrics import cohen_kappa_score\nimport pandas as pd\nimport tensorflow as tf\nfrom numpy import mean\n\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional\nfrom tensorflow.keras.models import Sequential, load_model, model_from_config\nimport tensorflow.keras.backend as K \nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n#from textblob import Word\nimport nltk\nnltk.download('averaged_perceptron_tagger') ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:08.054405Z","iopub.execute_input":"2022-11-25T10:05:08.054842Z","iopub.status.idle":"2022-11-25T10:05:28.097316Z","shell.execute_reply.started":"2022-11-25T10:05:08.054810Z","shell.execute_reply":"2022-11-25T10:05:28.096140Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n[nltk_data]     [Errno -3] Temporary failure in name resolution>\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"X=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.099804Z","iopub.execute_input":"2022-11-25T10:05:28.100291Z","iopub.status.idle":"2022-11-25T10:05:28.347304Z","shell.execute_reply.started":"2022-11-25T10:05:28.100236Z","shell.execute_reply":"2022-11-25T10:05:28.345995Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X1_train = X.loc[:int(len(X.index)*0.8)]\ny_train = X1_train[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']]\nX1_val = X.loc[int(len(X.index)*0.8)+1:int(len(X.index)*0.9)]\ny_val = X1_val[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']]\nX1_test = X.loc[int(len(X.index)*0.9)+1:]\ny_test = X1_test[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']] \n\n#X1_train is only for extracting out y for each set.","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.348620Z","iopub.execute_input":"2022-11-25T10:05:28.348968Z","iopub.status.idle":"2022-11-25T10:05:28.367972Z","shell.execute_reply.started":"2022-11-25T10:05:28.348932Z","shell.execute_reply":"2022-11-25T10:05:28.366768Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"IP=14\n\ny1_train=y_train[\"syntax\"]\ny2_train=y_train[\"cohesion\"]\ny3_train=y_train[\"vocabulary\"]\ny4_train=y_train[\"phraseology\"]\ny5_train=y_train[\"grammar\"]\ny6_train=y_train[\"conventions\"]\n\ny1_val=y_val[\"syntax\"]\ny2_val=y_val[\"cohesion\"]\ny3_val=y_val[\"vocabulary\"]\ny4_val=y_val[\"phraseology\"]\ny5_val=y_val[\"grammar\"]\ny6_val=y_val[\"conventions\"]\n\ny1_test=y_test[\"syntax\"]\ny2_test=y_test[\"cohesion\"]\ny3_test=y_test[\"vocabulary\"]\ny4_test=y_test[\"phraseology\"]\ny5_test=y_test[\"grammar\"]\ny6_test=y_test[\"conventions\"]\n\n\ny1_train = np.asarray(y1_train)\ny1_val = np.asarray(y1_val)  \n\ny2_train = np.asarray(y2_train)\ny2_val = np.asarray(y2_val)  \n\ny3_train = np.asarray(y3_train)\ny3_val = np.asarray(y3_val)  \n\ny4_train = np.asarray(y4_train)\ny4_val = np.asarray(y4_val)  \n\ny5_train = np.asarray(y5_train)\ny5_val = np.asarray(y5_val)  \n\ny6_train = np.asarray(y6_train)\ny6_val = np.asarray(y6_val)  \n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.370755Z","iopub.execute_input":"2022-11-25T10:05:28.371145Z","iopub.status.idle":"2022-11-25T10:05:28.385442Z","shell.execute_reply.started":"2022-11-25T10:05:28.371108Z","shell.execute_reply":"2022-11-25T10:05:28.384021Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def tokenize_sentences(data):\n    sent_token = nltk.tokenize.sent_tokenize(data)\n    return sent_token, len(sent_token)\n\n# calls the tokenize_sentences method and returns the total number of sentences\ndef sent_count(data):\n    return tokenize_sentences(data)[1]","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.386916Z","iopub.execute_input":"2022-11-25T10:05:28.387346Z","iopub.status.idle":"2022-11-25T10:05:28.400453Z","shell.execute_reply.started":"2022-11-25T10:05:28.387317Z","shell.execute_reply":"2022-11-25T10:05:28.399214Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def tokenize_words(data, punc=False, remove_stop_words=False, lower=True):\n    if lower:\n        word_tokens = nltk.tokenize.word_tokenize(data.lower())\n    else:\n        word_tokens = nltk.tokenize.word_tokenize(data)\n    if punc:\n        word_tokens = [word for word in word_tokens if word.isalnum()]\n    if remove_stop_words:\n        stop_words = get_stop_words()\n        word_tokens = [word for word in word_tokens if word not in stop_words]\n        \n    return word_tokens, list(set(word_tokens)), len(word_tokens)\n\n# calls the tokenize_words method and returns the total number of tokens\ndef word_count(data):\n    return tokenize_words(data)[2]","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.403149Z","iopub.execute_input":"2022-11-25T10:05:28.403538Z","iopub.status.idle":"2022-11-25T10:05:28.411402Z","shell.execute_reply.started":"2022-11-25T10:05:28.403506Z","shell.execute_reply":"2022-11-25T10:05:28.410056Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def token_frequency(words):\n    frequency_of_tokens = nltk.FreqDist(words)\n    return frequency_of_tokens","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.412716Z","iopub.execute_input":"2022-11-25T10:05:28.413044Z","iopub.status.idle":"2022-11-25T10:05:28.421580Z","shell.execute_reply.started":"2022-11-25T10:05:28.413015Z","shell.execute_reply":"2022-11-25T10:05:28.420490Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def token_length(data):\n    words = tokenize_words(data)[0]\n    len_of_tokens = {}\n    for word in words:\n        len_of_tokens[word] = len(word)\n    return len_of_tokens\n# calls the token_length method and returns the average of token lengths\ndef avg_length(words):\n    return statistics.mean(token_length(words).values())","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.422706Z","iopub.execute_input":"2022-11-25T10:05:28.423022Z","iopub.status.idle":"2022-11-25T10:05:28.432322Z","shell.execute_reply.started":"2022-11-25T10:05:28.422994Z","shell.execute_reply":"2022-11-25T10:05:28.431466Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def sentence_length(sent):\n    len_of_sent = []\n    for s in sent:\n        len_of_sent.append(tokenize_words(s)[2])\n    return len_of_sent, statistics.mean(len_of_sent)\ndef avg_word_sentence(data):\n        return sentence_length(tokenize_sentences(data)[0])[1]","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.433727Z","iopub.execute_input":"2022-11-25T10:05:28.434038Z","iopub.status.idle":"2022-11-25T10:05:28.446776Z","shell.execute_reply.started":"2022-11-25T10:05:28.434011Z","shell.execute_reply":"2022-11-25T10:05:28.445787Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def char_count(data):\n    return len(data.lower().replace(' ',''))","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.450694Z","iopub.execute_input":"2022-11-25T10:05:28.451672Z","iopub.status.idle":"2022-11-25T10:05:28.458322Z","shell.execute_reply.started":"2022-11-25T10:05:28.451634Z","shell.execute_reply":"2022-11-25T10:05:28.457499Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def pos_tags(data):\n    sent = tokenize_sentences(data)[0]\n    \n    noun_count = 0\n    adj_count = 0\n    verb_count = 0\n    adv_count = 0\n    adp_count=0\n    conj_count = 0\n    det_count = 0\n    prt_count = 0\n    pron_count = 0\n    punct_count=0\n    \n    \n    for s in sent:\n        tags = nltk.pos_tag(tokenize_words(s)[0])\n        #print(tags)\n        for tag in tags:\n            if tag[1][0] == 'N':\n                noun_count += 1\n            elif tag[1][0] == 'J':\n                adj_count += 1\n            elif tag[1][0] == 'V':\n                verb_count += 1\n            elif tag[1][0] == 'R':\n                adv_count += 1\n            elif tag[1] == 'IN':\n                adp_count += 1\n            elif tag[1] == 'CC':\n                conj_count += 1\n            elif tag[1] == 'DT':\n                det_count += 1\n            elif tag[1] == 'PRT':\n                prt_count += 1\n            elif tag[1] == 'PRP' or tag[1] == 'PRP$' :\n                pron_count += 1\n            elif tag[1] == '.':\n                punct_count += 1\n                \n    return noun_count,adj_count,verb_count,adv_count , adp_count , conj_count, det_count , pron_count , punct_count\n\n\npos_tags(\" new good on at relly already and or the some year home at on he their his say told ! \")","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.459759Z","iopub.execute_input":"2022-11-25T10:05:28.461727Z","iopub.status.idle":"2022-11-25T10:05:28.634478Z","shell.execute_reply.started":"2022-11-25T10:05:28.461688Z","shell.execute_reply":"2022-11-25T10:05:28.633481Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(3, 2, 1, 2, 4, 2, 2, 3, 1)"},"metadata":{}}]},{"cell_type":"code","source":"X['num_words'] = X['full_text'].apply(word_count)\ntest['num_words'] = test['full_text'].apply(word_count)\ntest.head()  \n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:28.635865Z","iopub.execute_input":"2022-11-25T10:05:28.636278Z","iopub.status.idle":"2022-11-25T10:05:39.907220Z","shell.execute_reply.started":"2022-11-25T10:05:28.636249Z","shell.execute_reply":"2022-11-25T10:05:39.906120Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  num_words\n0  0000C359D63E  when a person has no experience on a job their...        874\n1  000BAD50D026  Do you think students would benefit from being...        421\n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...        484","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>num_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n      <td>874</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n      <td>484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X['num_sents'] = X['full_text'].apply(sent_count)\ntest['num_sents'] = test['full_text'].apply(sent_count)\ntest.head()  ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:39.909032Z","iopub.execute_input":"2022-11-25T10:05:39.909747Z","iopub.status.idle":"2022-11-25T10:05:41.854734Z","shell.execute_reply.started":"2022-11-25T10:05:39.909713Z","shell.execute_reply":"2022-11-25T10:05:41.853478Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  num_words  \\\n0  0000C359D63E  when a person has no experience on a job their...        874   \n1  000BAD50D026  Do you think students would benefit from being...        421   \n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...        484   \n\n   num_sents  \n0         26  \n1         17  \n2         17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>num_words</th>\n      <th>num_sents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n      <td>874</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n      <td>421</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n      <td>484</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X['avg_word_sent'] = X['full_text'].apply(avg_word_sentence)\ntest['avg_word_sent'] = test['full_text'].apply(avg_word_sentence)\ntest.head()  ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:41.856047Z","iopub.execute_input":"2022-11-25T10:05:41.856374Z","iopub.status.idle":"2022-11-25T10:05:56.244201Z","shell.execute_reply.started":"2022-11-25T10:05:41.856344Z","shell.execute_reply":"2022-11-25T10:05:56.243115Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  num_words  \\\n0  0000C359D63E  when a person has no experience on a job their...        874   \n1  000BAD50D026  Do you think students would benefit from being...        421   \n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...        484   \n\n   num_sents  avg_word_sent  \n0         26      33.615385  \n1         17      24.764706  \n2         17      28.470588  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>num_words</th>\n      <th>num_sents</th>\n      <th>avg_word_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n      <td>874</td>\n      <td>26</td>\n      <td>33.615385</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n      <td>421</td>\n      <td>17</td>\n      <td>24.764706</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n      <td>484</td>\n      <td>17</td>\n      <td>28.470588</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X['noun_count'], X['adj_count'], X['verb_count'], X['adv_count'], X['adp_count'],X['conj_count'], X['det_count'], X['pron_count'], X['punct_count']  = zip(*X['full_text'].map(pos_tags))\n              \ntest['noun_count'], test['adj_count'], test['verb_count'], test['adv_count'], test['adp_count'],test['conj_count'], test['det_count'], test['pron_count'], test['punct_count']  = zip(*test['full_text'].map(pos_tags))\n                  ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:05:56.245646Z","iopub.execute_input":"2022-11-25T10:05:56.245995Z","iopub.status.idle":"2022-11-25T10:07:41.674611Z","shell.execute_reply.started":"2022-11-25T10:05:56.245964Z","shell.execute_reply":"2022-11-25T10:07:41.673229Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X.head()\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:41.676644Z","iopub.execute_input":"2022-11-25T10:07:41.677125Z","iopub.status.idle":"2022-11-25T10:07:41.695066Z","shell.execute_reply.started":"2022-11-25T10:07:41.677082Z","shell.execute_reply":"2022-11-25T10:07:41.693998Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  num_words  \\\n0  0000C359D63E  when a person has no experience on a job their...        874   \n1  000BAD50D026  Do you think students would benefit from being...        421   \n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...        484   \n\n   num_sents  avg_word_sent  noun_count  adj_count  verb_count  adv_count  \\\n0         26      33.615385         154         40         189         44   \n1         17      24.764706          88         14          87         18   \n2         17      28.470588          65         30         107         27   \n\n   adp_count  conj_count  det_count  pron_count  punct_count  \n0         90          22         97         111           26  \n1         54          19         19          59           17  \n2         54          14         25          73           17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>num_words</th>\n      <th>num_sents</th>\n      <th>avg_word_sent</th>\n      <th>noun_count</th>\n      <th>adj_count</th>\n      <th>verb_count</th>\n      <th>adv_count</th>\n      <th>adp_count</th>\n      <th>conj_count</th>\n      <th>det_count</th>\n      <th>pron_count</th>\n      <th>punct_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n      <td>874</td>\n      <td>26</td>\n      <td>33.615385</td>\n      <td>154</td>\n      <td>40</td>\n      <td>189</td>\n      <td>44</td>\n      <td>90</td>\n      <td>22</td>\n      <td>97</td>\n      <td>111</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n      <td>421</td>\n      <td>17</td>\n      <td>24.764706</td>\n      <td>88</td>\n      <td>14</td>\n      <td>87</td>\n      <td>18</td>\n      <td>54</td>\n      <td>19</td>\n      <td>19</td>\n      <td>59</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n      <td>484</td>\n      <td>17</td>\n      <td>28.470588</td>\n      <td>65</td>\n      <td>30</td>\n      <td>107</td>\n      <td>27</td>\n      <td>54</td>\n      <td>14</td>\n      <td>25</td>\n      <td>73</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features = X.iloc[:,8:]\nfinal_test = test.iloc[:,2:]\n# print(features.head)\nfeatures_array = np.asarray(features)\nfeatures_array_train = features_array[:3129]\nfeatures_array_val = features_array[3129:3129+391]\nfeatures_array_test = features_array[3129+391:]\nprint(features_array_test.shape)\nprint(features_array_val.shape)\nprint(features_array_train.shape)\nfinal_test.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:41.696650Z","iopub.execute_input":"2022-11-25T10:07:41.696975Z","iopub.status.idle":"2022-11-25T10:07:41.709092Z","shell.execute_reply.started":"2022-11-25T10:07:41.696947Z","shell.execute_reply":"2022-11-25T10:07:41.707917Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(391, 12)\n(391, 12)\n(3129, 12)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(3, 12)"},"metadata":{}}]},{"cell_type":"code","source":"\n\nrf1 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf2= RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf3 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf4 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf5 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf6 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n\nrf1.fit(features_array_train, y1_train)\nrf2.fit(features_array_train, y2_train)\nrf3.fit(features_array_train, y3_train)\nrf4.fit(features_array_train, y4_train)\nrf5.fit(features_array_train, y5_train)\nrf6.fit(features_array_train, y6_train)\n\n\n\ny1_pred = rf1.predict(features_array_test)\ny2_pred = rf2.predict(features_array_test)\ny3_pred = rf3.predict(features_array_test)\ny4_pred = rf4.predict(features_array_test)\ny5_pred = rf5.predict(features_array_test)\ny6_pred = rf6.predict(features_array_test)\n\ny1_pred = [round(r,1) for r in y1_pred]\ny2_pred = [round(r,1) for r in y2_pred]\ny3_pred = [round(r,1) for r in y3_pred]\ny4_pred = [round(r,1) for r in y4_pred]\ny5_pred = [round(r,1) for r in y5_pred]\ny6_pred = [round(r,1) for r in y6_pred]\n\n\nvalues1 = mean_squared_error(y1_pred, y1_test)\nvalues2 = mean_squared_error(y2_pred, y2_test)\nvalues3 = mean_squared_error(y3_pred, y3_test)\nvalues4 = mean_squared_error(y4_pred, y4_test)\nvalues5 = mean_squared_error(y5_pred, y5_test)\nvalues6 = mean_squared_error(y6_pred, y6_test)\n\n\nl=[(values1,values2,values3,values4,values5,values6)]\nprint(mean(l))","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:41.711254Z","iopub.execute_input":"2022-11-25T10:07:41.711677Z","iopub.status.idle":"2022-11-25T10:07:54.619023Z","shell.execute_reply.started":"2022-11-25T10:07:41.711606Z","shell.execute_reply":"2022-11-25T10:07:54.617868Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"0.3636189258312021\n","output_type":"stream"}]},{"cell_type":"code","source":"print(final_test.shape)\nfinal_test","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.620543Z","iopub.execute_input":"2022-11-25T10:07:54.621388Z","iopub.status.idle":"2022-11-25T10:07:54.636411Z","shell.execute_reply.started":"2022-11-25T10:07:54.621347Z","shell.execute_reply":"2022-11-25T10:07:54.635042Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(3, 12)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   num_words  num_sents  avg_word_sent  noun_count  adj_count  verb_count  \\\n0        874         26      33.615385         154         40         189   \n1        421         17      24.764706          88         14          87   \n2        484         17      28.470588          65         30         107   \n\n   adv_count  adp_count  conj_count  det_count  pron_count  punct_count  \n0         44         90          22         97         111           26  \n1         18         54          19         19          59           17  \n2         27         54          14         25          73           17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_words</th>\n      <th>num_sents</th>\n      <th>avg_word_sent</th>\n      <th>noun_count</th>\n      <th>adj_count</th>\n      <th>verb_count</th>\n      <th>adv_count</th>\n      <th>adp_count</th>\n      <th>conj_count</th>\n      <th>det_count</th>\n      <th>pron_count</th>\n      <th>punct_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>874</td>\n      <td>26</td>\n      <td>33.615385</td>\n      <td>154</td>\n      <td>40</td>\n      <td>189</td>\n      <td>44</td>\n      <td>90</td>\n      <td>22</td>\n      <td>97</td>\n      <td>111</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>421</td>\n      <td>17</td>\n      <td>24.764706</td>\n      <td>88</td>\n      <td>14</td>\n      <td>87</td>\n      <td>18</td>\n      <td>54</td>\n      <td>19</td>\n      <td>19</td>\n      <td>59</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>484</td>\n      <td>17</td>\n      <td>28.470588</td>\n      <td>65</td>\n      <td>30</td>\n      <td>107</td>\n      <td>27</td>\n      <td>54</td>\n      <td>14</td>\n      <td>25</td>\n      <td>73</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y1_pred = rf1.predict(final_test)\ny2_pred = rf2.predict(final_test)\ny3_pred = rf3.predict(final_test)\ny4_pred = rf4.predict(final_test)\ny5_pred = rf5.predict(final_test)\ny6_pred = rf6.predict(final_test)\n\n\ntest1 = [round(r,1) for r in y1_pred]\ntest2 = [round(r,1) for r in y2_pred]\ntest3 = [round(r,1) for r in y3_pred]\ntest4 = [round(r,1) for r in y4_pred]\ntest5 = [round(r,1) for r in y5_pred]\ntest6 = [round(r,1) for r in y6_pred]\n\n\nprint(test1)\nprint(test2)\nprint(test3)\nprint(test4)\nprint(test5)\nprint(test6)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.637629Z","iopub.execute_input":"2022-11-25T10:07:54.637941Z","iopub.status.idle":"2022-11-25T10:07:54.717471Z","shell.execute_reply.started":"2022-11-25T10:07:54.637912Z","shell.execute_reply":"2022-11-25T10:07:54.716253Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[3.2, 3.2, 3.3]\n[3.2, 3.4, 3.5]\n[3.2, 3.4, 3.4]\n[3.3, 3.4, 3.3]\n[2.9, 3.2, 3.2]\n[3.1, 3.2, 3.3]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","output_type":"stream"}]},{"cell_type":"code","source":"t1=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.718937Z","iopub.execute_input":"2022-11-25T10:07:54.719669Z","iopub.status.idle":"2022-11-25T10:07:54.730382Z","shell.execute_reply.started":"2022-11-25T10:07:54.719623Z","shell.execute_reply":"2022-11-25T10:07:54.729459Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"final=pd.DataFrame()\n\nfinal['text_id']=t1[\"text_id\"]\nfinal['syntax']=test1\nfinal['cohesion']=test2\nfinal['vocabulary']=test3\nfinal['phraseology']=test4\nfinal['grammar']=test5\nfinal['conventions']=test6  ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.733168Z","iopub.execute_input":"2022-11-25T10:07:54.733744Z","iopub.status.idle":"2022-11-25T10:07:54.744876Z","shell.execute_reply.started":"2022-11-25T10:07:54.733711Z","shell.execute_reply":"2022-11-25T10:07:54.743672Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"final.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.746058Z","iopub.execute_input":"2022-11-25T10:07:54.746504Z","iopub.status.idle":"2022-11-25T10:07:54.758895Z","shell.execute_reply.started":"2022-11-25T10:07:54.746450Z","shell.execute_reply":"2022-11-25T10:07:54.757793Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"final","metadata":{"execution":{"iopub.status.busy":"2022-11-25T10:07:54.759981Z","iopub.execute_input":"2022-11-25T10:07:54.760274Z","iopub.status.idle":"2022-11-25T10:07:54.777638Z","shell.execute_reply.started":"2022-11-25T10:07:54.760248Z","shell.execute_reply":"2022-11-25T10:07:54.776454Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        text_id  syntax  cohesion  vocabulary  phraseology  grammar  \\\n0  0000C359D63E     3.2       3.2         3.2          3.3      2.9   \n1  000BAD50D026     3.2       3.4         3.4          3.4      3.2   \n2  00367BB2546B     3.3       3.5         3.4          3.3      3.2   \n\n   conventions  \n0          3.1  \n1          3.2  \n2          3.3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>syntax</th>\n      <th>cohesion</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>3.3</td>\n      <td>2.9</td>\n      <td>3.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>3.2</td>\n      <td>3.4</td>\n      <td>3.4</td>\n      <td>3.4</td>\n      <td>3.2</td>\n      <td>3.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.3</td>\n      <td>3.5</td>\n      <td>3.4</td>\n      <td>3.3</td>\n      <td>3.2</td>\n      <td>3.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}